{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-11-26T14:12:01.929208Z","iopub.status.busy":"2025-11-26T14:12:01.928938Z","iopub.status.idle":"2025-11-26T14:12:02.239670Z","shell.execute_reply":"2025-11-26T14:12:02.239056Z","shell.execute_reply.started":"2025-11-26T14:12:01.929187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/testing/test_resume.pdf\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-11-26T14:12:02.241396Z","iopub.status.busy":"2025-11-26T14:12:02.240791Z","iopub.status.idle":"2025-11-26T14:13:26.966439Z","shell.execute_reply":"2025-11-26T14:13:26.965672Z","shell.execute_reply.started":"2025-11-26T14:12:02.241342Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n","pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n","pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["\n","!pip install -q streamlit ngrok pyngrok transformers==4.52.4 torch accelerate langchain langchain-community langchain-core pypdf PyPDF2\n","\n","# Install additional packages for PDF processing\n","!pip install -q pdf2image pillow"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-11-26T14:23:11.115982Z","iopub.status.busy":"2025-11-26T14:23:11.115366Z","iopub.status.idle":"2025-11-26T14:23:11.128582Z","shell.execute_reply":"2025-11-26T14:23:11.127714Z","shell.execute_reply.started":"2025-11-26T14:23:11.115958Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting app.py\n"]}],"source":["%%writefile app.py\n","import streamlit as st\n","import os\n","import tempfile\n","import json\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n","from langchain.prompts import PromptTemplate\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","import torch\n","import re\n","import base64\n","import time\n","\n","# Set page configuration\n","st.set_page_config(\n","    page_title=\"HR Resume Parser\",\n","    page_icon=\"ğŸ“„\",\n","    layout=\"wide\",\n","    initial_sidebar_state=\"expanded\"\n",")\n","\n","# Custom CSS for better styling\n","st.markdown(\"\"\"\n","<style>\n","    .main-header {\n","        font-size: 2.5rem;\n","        color: #1f77b4;\n","        text-align: center;\n","        margin-bottom: 2rem;\n","    }\n","    .success-box {\n","        padding: 1rem;\n","        border-radius: 0.5rem;\n","        background-color: #d4edda;\n","        border: 1px solid #c3e6cb;\n","        color: #155724;\n","    }\n","    .info-box {\n","        padding: 1rem;\n","        border-radius: 0.5rem;\n","        background-color: #d1ecf1;\n","        border: 1px solid #bee5eb;\n","        color: #0c5460;\n","    }\n","    .json-box {\n","        background-color: #f8f9fa;\n","        border: 1px solid #e9ecef;\n","        border-radius: 0.5rem;\n","        padding: 1rem;\n","        font-family: 'Courier New', monospace;\n","        font-size: 0.9rem;\n","    }\n","</style>\n","\"\"\", unsafe_allow_html=True)\n","\n","@st.cache_resource\n","def load_model():\n","    \"\"\"Load the model with caching to avoid reloading on every interaction\"\"\"\n","    st.info(\"ğŸ”„ Loading AI model... This may take a few minutes.\")\n","    model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        trust_remote_code=True\n","    )\n","    st.success(\"âœ… Model loaded successfully!\")\n","    return model, tokenizer\n","\n","def generate_text(prompt, max_new_tokens=800, temperature=0.7):\n","    \"\"\"Text generation function with better token management\"\"\"\n","    model, tokenizer = st.session_state.model\n","    \n","    # Tokenize the input\n","    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n","    \n","    # Calculate available tokens for generation\n","    input_length = inputs['input_ids'].shape[1]\n","    max_total_length = 4096  # Model's context window\n","    \n","    # Adjust max_new_tokens if needed\n","    if input_length + max_new_tokens > max_total_length:\n","        max_new_tokens = max_total_length - input_length - 10  # Leave some buffer\n","    \n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=max_new_tokens,\n","            do_sample=True,\n","            top_k=50,\n","            top_p=0.95,\n","            temperature=temperature,\n","            pad_token_id=tokenizer.eos_token_id,\n","            repetition_penalty=1.1\n","        )\n","    \n","    # Decode only the new tokens (skip the input/prompt)\n","    generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n","    return tokenizer.decode(generated_tokens, skip_special_tokens=True)\n","\n","def setup_parser():\n","    \"\"\"Set up the output parser\"\"\"\n","    full_name_schema = ResponseSchema(\n","        name=\"full_name\",\n","        description=\"The candidate's full name\"\n","    )\n","    email_schema = ResponseSchema(\n","        name=\"email\",\n","        description=\"The candidate's email address\"\n","    )\n","    education_schema = ResponseSchema(\n","        name=\"education\",\n","        description=\"List of education entries with degree, institution, and year\"\n","    )\n","    skills_schema = ResponseSchema(\n","        name=\"skills\",\n","        description=\"List of skills as strings\"\n","    )\n","    experience_schema = ResponseSchema(\n","        name=\"experience\", \n","        description=\"List of work experience entries with role, company, and years\"\n","    )\n","\n","    response_schemas = [\n","        full_name_schema,\n","        email_schema,\n","        education_schema,\n","        skills_schema,\n","        experience_schema\n","    ]\n","\n","    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","    format_instructions = output_parser.get_format_instructions()\n","    \n","    return output_parser, format_instructions\n","\n","def extract_text_from_pdf(pdf_path):\n","    \"\"\"Extract text from PDF file\"\"\"\n","    try:\n","        loader = PyPDFLoader(pdf_path)\n","        documents = loader.load()\n","        text = \"\\n\".join([doc.page_content for doc in documents])\n","        return text\n","    except Exception as e:\n","        st.error(f\"Error extracting text from PDF: {e}\")\n","        return None\n","\n","def clean_resume_text(text):\n","    \"\"\"Clean and preprocess the extracted resume text\"\"\"\n","    # Remove extra whitespace and newlines\n","    text = re.sub(r'\\n+', '\\n', text)\n","    text = re.sub(r' +', ' ', text)\n","    \n","    # Remove common PDF artifacts\n","    text = re.sub(r'\\x0c', '', text)  # Form feed characters\n","    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces\n","    \n","    return text.strip()\n","\n","def truncate_text(text, max_tokens=1500):\n","    \"\"\"Truncate text to fit within token limits\"\"\"\n","    tokenizer = st.session_state.model[1]\n","    tokens = tokenizer.encode(text)\n","    \n","    if len(tokens) > max_tokens:\n","        truncated_tokens = tokens[:max_tokens]\n","        return tokenizer.decode(truncated_tokens, skip_special_tokens=True)\n","    \n","    return text\n","\n","def extract_json_from_response(text):\n","    \"\"\"Extract JSON from model response\"\"\"\n","    pattern = r'```json\\s*(.*?)\\s*```'\n","    matches = re.findall(pattern, text, re.DOTALL)\n","    if matches:\n","        return matches[-1].strip()\n","    \n","    pattern = r'\\{.*\\}'\n","    matches = re.findall(pattern, text, re.DOTALL)\n","    if matches:\n","        return matches[-1].strip()\n","    \n","    return text\n","\n","def safe_get(data, key, default=\"N/A\"):\n","    \"\"\"Safely get value from dictionary with error handling\"\"\"\n","    if isinstance(data, dict):\n","        return data.get(key, default)\n","    return default\n","\n","def safe_display_education(education):\n","    \"\"\"Safely display education information with type checking\"\"\"\n","    if not education:\n","        st.write(\"No education information found\")\n","        return\n","    \n","    if isinstance(education, str):\n","        st.write(f\"**Education:** {education}\")\n","        return\n","    \n","    if isinstance(education, list):\n","        for i, edu in enumerate(education, 1):\n","            st.write(f\"**Education {i}:**\")\n","            if isinstance(edu, dict):\n","                st.write(f\"  - Degree: {safe_get(edu, 'degree')}\")\n","                st.write(f\"  - Institution: {safe_get(edu, 'institution')}\")\n","                st.write(f\"  - Year: {safe_get(edu, 'year')}\")\n","            else:\n","                st.write(f\"  - {str(edu)}\")\n","    else:\n","        st.write(f\"**Education:** {str(education)}\")\n","\n","def safe_display_experience(experience):\n","    \"\"\"Safely display experience information with type checking\"\"\"\n","    if not experience:\n","        st.write(\"No experience information found\")\n","        return\n","    \n","    if isinstance(experience, str):\n","        st.write(f\"**Experience:** {experience}\")\n","        return\n","    \n","    if isinstance(experience, list):\n","        for i, exp in enumerate(experience, 1):\n","            st.write(f\"**Experience {i}:**\")\n","            if isinstance(exp, dict):\n","                st.write(f\"  - Role: {safe_get(exp, 'role')}\")\n","                st.write(f\"  - Company: {safe_get(exp, 'company')}\")\n","                st.write(f\"  - Years: {safe_get(exp, 'years')}\")\n","            else:\n","                st.write(f\"  - {str(exp)}\")\n","    else:\n","        st.write(f\"**Experience:** {str(experience)}\")\n","\n","def safe_display_skills(skills):\n","    \"\"\"Safely display skills information with type checking\"\"\"\n","    if not skills:\n","        st.write(\"No skills information found\")\n","        return\n","    \n","    if isinstance(skills, str):\n","        st.write(f\"**Skills:** {skills}\")\n","        return\n","    \n","    if isinstance(skills, list):\n","        st.write(\"**Skills:**\")\n","        for skill in skills:\n","            st.write(f\"  - {str(skill)}\")\n","    else:\n","        st.write(f\"**Skills:** {str(skills)}\")\n","\n","def parse_resume_from_pdf(pdf_file):\n","    \"\"\"Parse PDF resume into structured JSON\"\"\"\n","    try:\n","        # Save uploaded file to temporary file\n","        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n","            tmp_file.write(pdf_file.getvalue())\n","            tmp_path = tmp_file.name\n","\n","        # Extract text from PDF\n","        resume_text = extract_text_from_pdf(tmp_path)\n","        if not resume_text:\n","            st.error(\"âŒ Could not extract text from PDF\")\n","            return None\n","\n","        # Clean the text\n","        cleaned_text = clean_resume_text(resume_text)\n","        \n","        # Show text preview\n","        with st.expander(\"ğŸ“ Extracted Text Preview\"):\n","            st.text_area(\"Raw extracted text\", cleaned_text[:1000] + \"...\" if len(cleaned_text) > 1000 else cleaned_text, height=200)\n","        \n","        # Truncate text if too long\n","        if len(cleaned_text) > 3000:  # Rough character count estimate\n","            st.warning(\"âš ï¸ Resume text is long. Truncating to fit model limits...\")\n","            cleaned_text = truncate_text(cleaned_text, max_tokens=1200)\n","        \n","        # Create prompt\n","        output_parser, format_instructions = st.session_state.parser\n","        \n","        resume_parsing_template = \"\"\"\n","You are an HR assistant that extracts candidate information from resume text.\n","\n","Extract the following information from the resume text:\n","- Full name\n","- Email address\n","- Education history (list of degrees with institution and year)\n","- Skills (list of strings)\n","- Work experience (list of roles with company and years)\n","\n","Format the education as: [{{\"degree\": \"degree name\", \"institution\": \"institution name\", \"year\": \"graduation year\"}}]\n","Format the experience as: [{{\"role\": \"job title\", \"company\": \"company name\", \"years\": \"employment years\"}}]\n","\n","Respond ONLY in JSON format as follows:\n","\n","{format_instructions}\n","\n","Now extract from the following resume text:\n","\"{resume_text}\"\n","\"\"\"\n","\n","        prompt = PromptTemplate(\n","            template=resume_parsing_template,\n","            input_variables=[\"resume_text\", \"format_instructions\"]\n","        ).format(resume_text=cleaned_text, format_instructions=format_instructions)\n","\n","        # Show token count info\n","        tokenizer = st.session_state.model[1]\n","        prompt_tokens = len(tokenizer.encode(prompt))\n","        st.info(f\"ğŸ“Š Prompt length: {prompt_tokens} tokens (max: 4096)\")\n","\n","        # Generate response with progress\n","        with st.spinner(\"ğŸ¤– AI is parsing the resume... This may take 30-60 seconds.\"):\n","            progress_bar = st.progress(0)\n","            \n","            for i in range(100):\n","                time.sleep(0.3)  # Simulate progress\n","                progress_bar.progress(i + 1)\n","            \n","            response = generate_text(prompt, max_new_tokens=800)\n","        \n","        # Extract JSON from response\n","        json_text = extract_json_from_response(response)\n","        \n","        # Parse the JSON\n","        try:\n","            output_data = output_parser.parse(f\"```json\\n{json_text}\\n```\")\n","        except Exception as e:\n","            st.error(f\"âŒ Error parsing JSON response: {e}\")\n","            st.code(response, language='text')\n","            return None\n","        \n","        # Clean up temporary file\n","        os.unlink(tmp_path)\n","        \n","        return output_data\n","        \n","    except Exception as e:\n","        st.error(f\"âŒ Error parsing resume: {e}\")\n","        # Clean up temporary file in case of error\n","        if 'tmp_path' in locals():\n","            try:\n","                os.unlink(tmp_path)\n","            except:\n","                pass\n","        return None\n","\n","def get_download_link(data, filename):\n","    \"\"\"Generate a download link for JSON data\"\"\"\n","    json_str = json.dumps(data, indent=2)\n","    b64 = base64.b64encode(json_str.encode()).decode()\n","    href = f'<a href=\"data:application/json;base64,{b64}\" download=\"{filename}\" style=\"background-color: #4CAF50; color: white; padding: 10px 20px; text-align: center; text-decoration: none; display: inline-block; border-radius: 5px;\">Download JSON</a>'\n","    return href\n","\n","# Main application\n","def main():\n","    st.markdown('<h1 class=\"main-header\">ğŸ¤– HR Candidate Profile Parser</h1>', unsafe_allow_html=True)\n","    \n","    # Initialize session state\n","    if 'model' not in st.session_state:\n","        st.session_state.model = load_model()\n","    if 'parser' not in st.session_state:\n","        st.session_state.parser = setup_parser()\n","    \n","    # Sidebar\n","    st.sidebar.title(\"About\")\n","    st.sidebar.info(\n","        \"This AI-powered tool extracts structured information from resume PDFs including:\\n\\n\"\n","        \"â€¢ Personal details (name, email)\\n\"\n","        \"â€¢ Education history\\n\" \n","        \"â€¢ Skills\\n\"\n","        \"â€¢ Work experience\\n\\n\"\n","        \"Upload a resume PDF to get started!\"\n","    )\n","    \n","    st.sidebar.markdown(\"---\")\n","    st.sidebar.subheader(\"How to use:\")\n","    st.sidebar.write(\"1. Upload a resume PDF file\")\n","    st.sidebar.write(\"2. Wait for AI processing (30-60 seconds)\")\n","    st.sidebar.write(\"3. View and download the parsed data\")\n","    \n","    st.sidebar.markdown(\"---\")\n","    st.sidebar.subheader(\"Tips:\")\n","    st.sidebar.write(\"â€¢ Use clear, text-based PDFs for best results\")\n","    st.sidebar.write(\"â€¢ Avoid scanned/image-only PDFs\")\n","    st.sidebar.write(\"â€¢ Keep resumes under 3 pages for optimal parsing\")\n","    \n","    # Main content\n","    col1, col2 = st.columns([1, 1])\n","    \n","    with col1:\n","        st.subheader(\"ğŸ“¤ Upload Resume\")\n","        uploaded_file = st.file_uploader(\n","            \"Choose a PDF file\", \n","            type=\"pdf\",\n","            help=\"Upload a resume in PDF format (text-based PDFs work best)\"\n","        )\n","        \n","        if uploaded_file is not None:\n","            st.info(f\"ğŸ“„ File uploaded: {uploaded_file.name}\")\n","            st.write(f\"File size: {uploaded_file.size / 1024:.2f} KB\")\n","            \n","            if st.button(\"ğŸš€ Parse Resume\", type=\"primary\", use_container_width=True):\n","                result = parse_resume_from_pdf(uploaded_file)\n","                \n","                if result:\n","                    st.session_state.result = result\n","                    st.session_state.filename = uploaded_file.name.replace('.pdf', '_parsed.json')\n","                    st.success(\"âœ… Resume parsed successfully!\")\n","                else:\n","                    st.error(\"âŒ Failed to parse resume. Please try with a different file.\")\n","    \n","    with col2:\n","        st.subheader(\"ğŸ“Š Parsed Results\")\n","        \n","        if 'result' in st.session_state:\n","            result = st.session_state.result\n","            \n","            # Display results in expandable sections\n","            with st.expander(\"ğŸ‘¤ Personal Information\", expanded=True):\n","                st.write(f\"**Full Name:** {safe_get(result, 'full_name')}\")\n","                st.write(f\"**Email:** {safe_get(result, 'email')}\")\n","            \n","            with st.expander(\"ğŸ“ Education\", expanded=True):\n","                education = safe_get(result, 'education', [])\n","                safe_display_education(education)\n","            \n","            with st.expander(\"ğŸ’¼ Skills\", expanded=True):\n","                skills = safe_get(result, 'skills', [])\n","                safe_display_skills(skills)\n","            \n","            with st.expander(\"ğŸ’¼ Work Experience\", expanded=True):\n","                experience = safe_get(result, 'experience', [])\n","                safe_display_experience(experience)\n","            \n","            # Raw JSON view\n","            with st.expander(\"ğŸ“‹ Raw JSON Output\"):\n","                st.code(json.dumps(result, indent=2), language='json')\n","            \n","            # Download button\n","            st.markdown(\"---\")\n","            st.markdown(\"### ğŸ“¥ Download Results\")\n","            st.markdown(get_download_link(result, st.session_state.filename), unsafe_allow_html=True)\n","        \n","        else:\n","            st.info(\"ğŸ‘† Upload a PDF resume and click 'Parse Resume' to see results here\")\n","            \n","            # Show sample output\n","            with st.expander(\"ğŸ“‹ Example Output Format\"):\n","                sample_output = {\n","                    \"full_name\": \"John Smith\",\n","                    \"email\": \"john.smith@email.com\",\n","                    \"education\": [\n","                        {\"degree\": \"B.Sc. Computer Science\", \"institution\": \"MIT\", \"year\": \"2020\"}\n","                    ],\n","                    \"skills\": [\"Python\", \"Machine Learning\", \"Data Analysis\"],\n","                    \"experience\": [\n","                        {\"role\": \"Software Engineer\", \"company\": \"Google\", \"years\": \"2020-2023\"}\n","                    ]\n","                }\n","                st.json(sample_output)\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-11-26T14:23:12.538637Z","iopub.status.busy":"2025-11-26T14:23:12.538130Z","iopub.status.idle":"2025-11-26T14:23:29.287882Z","shell.execute_reply":"2025-11-26T14:23:29.287243Z","shell.execute_reply.started":"2025-11-26T14:23:12.538611Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Ngrok authentication configured\n","ğŸš€ Starting Fixed HR Resume Parser on port 8503...\n","â³ Waiting for app to initialize...\n","\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\n"]},{"name":"stderr","output_type":"stream","text":["2025-11-26 14:23:14.328 Port 8503 is already in use\n"]},{"name":"stdout","output_type":"stream","text":["Streamlit error: Command '['streamlit', 'run', 'app.py', '--server.port', '8503', '--server.address', '0.0.0.0', '--server.headless', 'true', '--server.enableCORS', 'false', '--server.enableXsrfProtection', 'false']' returned non-zero exit status 1.\n","ğŸ”— Setting up ngrok tunnel...\n","âœ… Ngrok tunnel created!\n","ğŸŒ Your Fixed HR Resume Parser is live at: https://unchevroned-unprofited-cherie.ngrok-free.dev\n"]},{"data":{"text/html":["\n","    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0;\">\n","        <h2 style=\"color: white; margin: 0;\">ğŸ‰ Fixed HR Resume Parser is Ready!</h2>\n","        <h3 style=\"color: white; margin: 10px 0;\">\n","            <a href=\"https://unchevroned-unprofited-cherie.ngrok-free.dev\" target=\"_blank\" style=\"color: #ffd700; text-decoration: none;\">\n","                ğŸ‘‰ Click here to open your app ğŸ‘ˆ\n","            </a>\n","        </h3>\n","        <p style=\"color: white; margin: 0;\">Share this URL: <code style=\"background: rgba(255,255,255,0.2); padding: 5px; border-radius: 3px;\">https://unchevroned-unprofited-cherie.ngrok-free.dev</code></p>\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","ğŸ“Š Deployment Status:\n","âœ… Public URL: https://unchevroned-unprofited-cherie.ngrok-free.dev\n","âœ… Port: 8503\n","âœ… Token Limit: Fixed (max_new_tokens=800)\n","âœ… Text Truncation: Enabled for long resumes\n","âœ… App is responding correctly!\n","\n","ğŸ›¡ï¸ Ngrok tunnel is active. The app will remain accessible until you stop this notebook.\n","ğŸ’¡ Fixed Features:\n","   - Token limit management\n","   - Text truncation for long resumes\n","   - Progress bars\n","   - Better error handling\n","\n","ğŸ›‘ To stop: Interrupt the notebook kernel\n"]},{"name":"stderr","output_type":"stream","text":["/kaggle/working/app.py:8: LangChainDeprecationWarning: Importing PyPDFLoader from langchain.document_loaders is deprecated. Please replace deprecated imports:\n","\n",">> from langchain.document_loaders import PyPDFLoader\n","\n","with new imports of:\n","\n",">> from langchain_community.document_loaders import PyPDFLoader\n","You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n","  from langchain.document_loaders import PyPDFLoader\n","/kaggle/working/app.py:8: LangChainDeprecationWarning: Importing PyPDFLoader from langchain.document_loaders is deprecated. Please replace deprecated imports:\n","\n",">> from langchain.document_loaders import PyPDFLoader\n","\n","with new imports of:\n","\n",">> from langchain_community.document_loaders import PyPDFLoader\n","You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n","  from langchain.document_loaders import PyPDFLoader\n","/kaggle/working/app.py:8: LangChainDeprecationWarning: Importing PyPDFLoader from langchain.document_loaders is deprecated. Please replace deprecated imports:\n","\n",">> from langchain.document_loaders import PyPDFLoader\n","\n","with new imports of:\n","\n",">> from langchain_community.document_loaders import PyPDFLoader\n","You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n","  from langchain.document_loaders import PyPDFLoader\n"]}],"source":["# Set up ngrok deployment for port 8503 with fixed app\n","from pyngrok import ngrok\n","import nest_asyncio\n","import threading\n","import time\n","from IPython.display import HTML, display\n","import requests\n","import subprocess\n","\n","# Apply nest_asyncio to avoid asyncio conflicts\n","nest_asyncio.apply()\n","\n","# Set your ngrok authtoken\n","NGROK_AUTH_TOKEN = \"361wHtfwQwKIcTnjupQkQyXTq6t_7pRbH53TaUSroDfafZX7m\"\n","\n","if NGROK_AUTH_TOKEN:\n","    try:\n","        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","        print(\"âœ… Ngrok authentication configured\")\n","    except Exception as e:\n","        print(f\"âŒ Ngrok auth error: {e}\")\n","        print(\"âš ï¸  Continuing without authentication\")\n","\n","# Kill any existing ngrok processes\n","ngrok.kill()\n","\n","# Define the Streamlit port\n","PORT = 8503\n","\n","# Function to run Streamlit\n","def run_streamlit():\n","    try:\n","        # Run streamlit app on port 8503 with the fixed app\n","        subprocess.run([\n","            'streamlit', 'run', 'app.py', \n","            '--server.port', str(PORT), \n","            '--server.address', '0.0.0.0',\n","            '--server.headless', 'true', \n","            '--server.enableCORS', 'false',\n","            '--server.enableXsrfProtection', 'false'\n","        ], check=True)\n","    except Exception as e:\n","        print(f\"Streamlit error: {e}\")\n","\n","# Start Streamlit in a separate thread\n","print(\"ğŸš€ Starting Fixed HR Resume Parser on port 8503...\")\n","streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)\n","streamlit_thread.start()\n","\n","# Wait for Streamlit to start\n","print(\"â³ Waiting for app to initialize...\")\n","time.sleep(15)\n","\n","# Create ngrok tunnel for port 8503\n","print(\"ğŸ”— Setting up ngrok tunnel...\")\n","try:\n","    public_url = ngrok.connect(PORT, bind_tls=True)\n","    print(f\"âœ… Ngrok tunnel created!\")\n","    \n","    # Get the public URL\n","    ngrok_url = public_url.public_url\n","    print(f\"ğŸŒ Your Fixed HR Resume Parser is live at: {ngrok_url}\")\n","\n","    # Display the URL with clickable link\n","    display(HTML(f'''\n","    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0;\">\n","        <h2 style=\"color: white; margin: 0;\">ğŸ‰ Fixed HR Resume Parser is Ready!</h2>\n","        <h3 style=\"color: white; margin: 10px 0;\">\n","            <a href=\"{ngrok_url}\" target=\"_blank\" style=\"color: #ffd700; text-decoration: none;\">\n","                ğŸ‘‰ Click here to open your app ğŸ‘ˆ\n","            </a>\n","        </h3>\n","        <p style=\"color: white; margin: 0;\">Share this URL: <code style=\"background: rgba(255,255,255,0.2); padding: 5px; border-radius: 3px;\">{ngrok_url}</code></p>\n","    </div>\n","    '''))\n","\n","    # Show deployment info\n","    print(\"\\nğŸ“Š Deployment Status:\")\n","    print(f\"âœ… Public URL: {ngrok_url}\")\n","    print(f\"âœ… Port: {PORT}\")\n","    print(f\"âœ… Token Limit: Fixed (max_new_tokens=800)\")\n","    print(f\"âœ… Text Truncation: Enabled for long resumes\")\n","\n","    # Test the connection\n","    try:\n","        response = requests.get(f\"{ngrok_url}\", timeout=10)\n","        if response.status_code == 200:\n","            print(\"âœ… App is responding correctly!\")\n","        else:\n","            print(f\"âš ï¸ App returned status code: {response.status_code}\")\n","    except Exception as e:\n","        print(f\"âŒ Could not reach app: {e}\")\n","\n","    # Keep-alive message\n","    print(\"\\nğŸ›¡ï¸ Ngrok tunnel is active. The app will remain accessible until you stop this notebook.\")\n","    print(\"ğŸ’¡ Fixed Features:\")\n","    print(\"   - Token limit management\")\n","    print(\"   - Text truncation for long resumes\")\n","    print(\"   - Progress bars\")\n","    print(\"   - Better error handling\")\n","    print(\"\\nğŸ›‘ To stop: Interrupt the notebook kernel\")\n","\n","except Exception as e:\n","    print(f\"âŒ Failed to create ngrok tunnel: {e}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":8757927,"sourceId":13762193,"sourceType":"datasetVersion"}],"dockerImageVersionId":31193,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":4}
